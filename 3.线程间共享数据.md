如何共享数据只读，那就不会影响到数据  

## 线程间共享数据存在的问题

* 不变量（invariant）：关于一个特定数据结构总为true的语句，比如`双向链表的两个相邻节点A和B，A的后指针一定指向B，B的前指针一定指向A`。有时程序为了方便会暂时破坏不变量，这通常发生于更新复杂数据结构的过程中，比如删除双向链表中的一个节点N，要先让N的前一个节点指向N的后一个节点（不变量被破坏），再让N的后节点指向前节点，最后删除N（此时不变量重新恢复）
* 线程修改共享数据时，就会发生破坏不变量的情况，此时如果有其他线程访问，就可能导致不变量被永久性破坏，这就是race condition
* 如果线程执行顺序的先后对结果无影响，则为不需要关心的良性竞争。需要关心的是不变量被破坏时产生的race condition
* C++标准中定义了data race的概念，指代一种特定的race condition，即并发修改单个对象。data race会造成未定义行为
* race condition要求一个线程进行时，另一线程访问同一数据块，出现问题时很难复现，因此编程时需要使用大量复杂操作来避免race condition

## 用mutex保护共享数据

* 使用mutex在访问共享数据前加锁，访问结束后解锁。一个线程用特定的mutex锁定后，其他线程必须等待该线程的mutex解锁才能访问共享数据
* C++提供了[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)来创建一个mutex，可通过[std::mutex::lock](https://en.cppreference.com/w/cpp/thread/mutex/lock)加锁，通过[std::unlock](https://en.cppreference.com/w/cpp/thread/mutex/unlock)解锁，但一般不直接使用这两个函数
* [std::lock_guard](https://en.cppreference.com/w/cpp/thread/lock_guard)是一个用[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)构造的RAII模板类

```cpp
#include <list>
#include <mutex>
#include <algorithm>

std::list<int> v;
std::mutex m;

void f(int n)
{
  std::lock_guard<std::mutex> l(m); // C++17中引入了类模板实参推断，可简写为std::lock_guard l(m);
  v.emplace_back(n);
}

bool listContains(int n)
{
  std::lock_guard<std::mutex> l(m);
  return std::find(std::begin(v), std::end(v), n) != std::end(v);
}
```

* C++17提供了加强版的[std::scoped_lock](https://en.cppreference.com/w/cpp/thread/scoped_lock)，它可以接受任意数量的[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)，可完全取代[std::lock_guard](https://en.cppreference.com/w/cpp/thread/lock_guard)

```cpp
std::scoped_lock g(m1, m2);
```

* 一般mutex和要保护的数据一起放在类中，定义为private数据成员，而非全局变量，这样能让代码更清晰。但如果某个成员函数返回指向数据成员的指针或引用，则通过这个指针的访问行为不会被mutex限制，因此需要谨慎设置接口，确保mutex能锁住数据

```cpp
class A {
 private:
  int i;
 public:
  void doSomething();
};

class B {
 private:
  A data;
  std::mutex m;
 public:
  template<typename F>
  void processData(F f)
  {
    std::scoped_lock l(m);
    f(data);
  }
};

A* p;
void oops(A& a)
{
  p = &a;
}

B b;
void foo()
{
  b.processData(oops); // processData加了mutex，但传入该函数会获取指向数据成员的指针
  p->doSomething(); // 未锁定mutex的情况下访问数据
}
```

* 即便在很简单的接口中，也可能遇到race condition

```cpp
std::stack<int> s；
if (!s.empty())
{
  int n = s.top();
  s.pop();
}
```

* 上述代码先检查非空再获取栈顶元素，在单线程中是安全的，但在多线程中，检查非空之后，如果其他线程先pop，就会导致当前线程top出错。这是一个经典的race condition，即使用mutex也不能阻止，这就是接口固有的问题，解决方法是改变接口的设计
* 另一个潜在的竞争是，如果两个线程都还没pop，而是分别获取了top，虽然不会产生未定义行为，但这种对同一值处理了两次的行为更为严重，因为看起来没有任何错误，很难定位bug
* 思考一个问题，既然如此，为什么不直接让pop返回栈顶元素。原因在于，假设有一个`stack<vector<int>>`，拷贝vector时需要在堆上分配内存，如果系统负载严重或资源有限（比如vector有大量元素），vector的拷贝构造函数就会抛出[std::bad_alloc](https://en.cppreference.com/w/cpp/memory/new/bad_alloc)异常。如果pop可以返回栈顶元素值，返回一定是最后执行的语句，stack在返回前已经弹出了元素，但如果拷贝返回值时抛出异常，就会导致弹出的数据丢失（从栈上移除但拷贝失败）。因此[std::stack](https://en.cppreference.com/w/cpp/container/stack)的设计者将这个操作分解为top和pop两部分，但这样的分割却造成了race condition
* 下面思考几种把top和pop合为一步的方法。第一种方法是传入一个参数获取结果值

```cpp
std::vector<int> res;
s.pop(res);
```

* 这种方式的明显缺点是，需要构造一个栈元素类型的实例，这是不现实的：为了获取结果而临时构造一个对象并不划算、元素类型可能不支持赋值（比如用户自定义某个类型）、构造函数还需要一些参数......
* 第二种方案是为元素类型设置不抛异常的拷贝或移动构造函数，使用[std::is_nothrow_copy_constructible](https://en.cppreference.com/w/cpp/types/is_copy_constructible)和[std::is_nothrow_move_constructible](https://en.cppreference.com/w/cpp/types/is_move_constructible)即可保证不抛异常，因为pop返回值时只担心该过程抛异常。但这种方式过于局限，抛异常的构造函数还是更常见的，这些类型也希望能存入stack
* 第三种方案是返回指向弹出元素的指针，指针可以自由拷贝且不会抛异常。这需要管理对象的内存分配，使用[std::shared_ptr](https://en.cppreference.com/w/cpp/memory/shared_ptr)是个不错的选择，但这个方案的开销太大，尤其是对于内置类型
* 第四种方案是结合方案一二或者一三，比如结合方案一三实现一个线程安全的stack

```cpp
#include <exception>
#include <memory>
#include <mutex>
#include <stack>

struct emptyStack : std::exception
{
  const char* what() const noexcept
  {
    return "empty stack!";
  }
};

template<typename T>
class A {
 private:
  std::stack<T> s;
  mutable std::mutex m;
 public:
  A() : s(std::stack<T>()) {}
  
  A(const A& rhs)
  {
    std::lock_guard<std::mutex> l(rhs.m);
    s = rhs.s;
  }
  
  A& operator=(const A&) = delete;
  
  void push(T n)
  {
    std::lock_guard<std::mutex> l(m);
    s.push(std::move(n));
  }
  
  std::shared_ptr<T> pop() // 返回一个指向栈顶元素的指针
  {
    std::lock_guard<std::mutex> l(m);
    if (s.empty()) throw emptyStack();
    const std::shared_ptr<T> res(std::make_shared<T>(std::move(s.top())));
    s.pop();
    return res;
  }
  
  void pop(T& n) // 传引用获取结果
  {
    std::lock_guard<std::mutex> l(m);
    if (s.empty()) throw emptyStack();
    n = std::move(s.top());
    s.pop();
  }
  
  bool empty() const
  {
    std::lock_guard<std::mutex> l(m);
    return s.empty();
  }
};
```

* 之前锁的粒度（锁保护的数据量大小）太小，保护操作覆盖不周全，这里的粒度就较大，覆盖了大量操作。但并非粒度越大越好，如果锁粒度太大，过多线程请求竞争占用资源时，并发的性能提升就被抵消掉了
* 如果给定操作需要多个mutex时，就会引入一个新的潜在问题，即死锁

## 死锁

* 死锁的四个必要条件：互斥、占有且等待、不可抢占、循环等待
* 避免死锁通常建议让两个mutex以相同顺序上锁，总是先锁A再锁B，但这并不适用所有情况
* [std::lock](https://en.cppreference.com/w/cpp/thread/lock)解决了此问题，它可以一次性锁住多个mutex，并且没有死锁风险

```cpp
class A {
 public:
  explicit A(int x) : i(x) {}
  int i;
  std::mutex m;
};

void f(A& from, A& to, int n)
{
  std::lock(from.m, to.m);
  // 下面按固定顺序加锁，看似不会有死锁的问题
  // 但如果没有std::lock同时上锁
  // 另一线程中执行f(to, from, n)
  // 两个锁的顺序就反了过来，从而可能导致死锁
  std::lock_guard<std::mutex> lock1(from.m, std::adopt_lock); // std::adopt_lock表示获取m的所有权
  std::lock_guard<std::mutex> lock2(to.m, std::adopt_lock);
  from.i -= n;
  to.i += n;
}

int main()
{
  A x(70);
  A y(30);
  
  std::thread t1(f, std::ref(x), std::ref(y), 5);
  std::thread t2(f, std::ref(y), std::ref(x), 10);
  
  t1.join();
  t2.join();
}
```

* [std::lock](https://en.cppreference.com/w/cpp/thread/lock)可能抛异常，此时就不会上锁，因此要么都锁住，要么都不锁
* 也可以使用[std::unique_lock](https://en.cppreference.com/w/cpp/thread/unique_lock)，它比[std::lock_guard](https://en.cppreference.com/w/cpp/thread/lock_guard)灵活，可以传入[std::adopt_lock](https://en.cppreference.com/w/cpp/thread/lock_tag)管理mutex，也可以传入[std::defer_lock](https://en.cppreference.com/w/cpp/thread/lock_tag)表示mutex应保持解锁状态，以使mutex能被[std::unique_lock::lock](https://en.cppreference.com/w/cpp/thread/unique_lock/lock)获取，或可以把[std::unique_lock](https://en.cppreference.com/w/cpp/thread/unique_lock)传给[std::lock](https://en.cppreference.com/w/cpp/thread/lock)

```cpp
std::unique_lock<std::mutex> lock1(from.m, std::defer_lock);
std::unique_lock<std::mutex> lock2(to.m, std::defer_lock);
// std::defer_lock表示不获取m的所有权，因此m还未上锁
std::lock(lock1, lock2); // 此处上锁
```

* [std::unique_lock](https://en.cppreference.com/w/cpp/thread/unique_lock)比[std::lock_guard](https://en.cppreference.com/w/cpp/thread/lock_guard)占用的空间多，会稍慢一点，如果不需要更灵活的锁，依然可以使用[std::lock_guard](https://en.cppreference.com/w/cpp/thread/lock_guard)。上面展示了延迟锁的情况，另一种要求灵活性的情况是转移锁的所有权到另一个作用域

```cpp
std::unique_lock<std::mutex> getLock()
{
  extern std::mutex m;
  std::unique_lock<std::mutex> l(m);
  prepareData();
  return l; // 不需要std::move（编译器负责调用移动构造函数）
}

void f()
{
  std::unique_lock<std::mutex> l(getLock());
  doSomething();
}
```

* 对一些费时的操作（如文件IO）上锁可能造成很多操作被阻塞，可以在面对这些操作时先解锁

```cpp
void f()
{
  std::unique_lock<std::mutex> l(m);
  auto data = getData();
  l.unlock(); // 费时操作没有必要持有锁，先解锁
  auto res = process(data);
  l.lock(); // 为了写入数据再次上锁
  writeResult(data, res);
}
```

* 如果支持C++17，最易最优的同时上锁方法是使用[std::scoped_lock](https://en.cppreference.com/w/cpp/thread/scoped_lock)

```cpp
std::scoped_lock l(from.m, to.m);
```

* 解决死锁并不简单，[std::lock](https://en.cppreference.com/w/cpp/thread/lock)和[std::scoped_lock](https://en.cppreference.com/w/cpp/thread/scoped_lock)无法获取其中的锁，此时解决死锁更依赖于开发者的能力
* 第一个避免死锁的建议是，一个线程已经获取一个锁时就不要获取第二个。如果每个线程只有一个锁，锁上就不会产生死锁（但除了互斥锁，其他方面也可能造成死锁，比如即使无锁，线程间相互等待也可能造成死锁）
* 第二个建议是，持有锁时避免调用用户提供的代码。用户提供的代码可能做任何时，包括获取锁，如果持有锁时调用用户代码获取锁，就会违反第一个建议，并造成死锁。但有时调用用户代码是无法避免的
* 第三个建议是，按固定顺序获取锁。如果必须获取多个锁且不能用[std::lock](https://en.cppreference.com/w/cpp/thread/lock)同时获取，最好在每个线程上用固定顺序获取。上面的例子虽然是按固定顺序获取锁，但如果不同时加锁就会出现死锁，对于这种情况的建议是额外规定固定的调用顺序
* 第四个建议是使用层次锁，如果一个锁被低层持有，就不允许再上锁

```cpp
// 设定值来表示层级
hierarchical_mutex high(10000);
hierarchical_mutex mid(6000);
hierarchical_mutex low(5000);

void lf() // 最低层函数
{
  std::scoped_lock l(low);
}

void hf()
{
  std::scoped_lock l(high);
  lf(); // 可以调用低层函数
}

void mf()
{
  std::scoped_lock l(mid);
  hf(); // 中层调用了高层函数，违反了层次结构
}
```

* 下面实现hierarchical_mutex

```cpp
class hierarchical_mutex {
  std::mutex internal_mutex;
  const unsigned long hierarchy_value; // 当前层级值
  unsigned long previous_hierarchy_value; // 前一线程的层级值
  // 所在线程的层级值，thread_local表示值存在于线程存储期
  static thread_local unsigned long this_thread_hierarchy_value;
  void check_for_hierarchy_violation() // 检查是否违反层级结构
  {
    if (this_thread_hierarchy_value <= hierarchy_value)
    {
      throw std::logic_error("mutex hierarchy violated");
    }
  }
  void update_hierarchy_value()
  {
    // 先存储当前线程的层级值（用于解锁时恢复）
    previous_hierarchy_value = this_thread_hierarchy_value;
    // 再把其设为锁的层级值
    this_thread_hierarchy_value = hierarchy_value;
  }
 public:
  explicit hierarchical_mutex(unsigned long value) :
    hierarchy_value(value), previous_hierarchy_value(0)
  {}
  void lock()
  {
    check_for_hierarchy_violation(); // 要求线程层级值大于锁的层级值
    internal_mutex.lock(); // 内部锁被锁住
    update_hierarchy_value(); // 更新层级值
  }
  void unlock()
  {
    if (this_thread_hierarchy_value != hierarchy_value)
    {
      throw std::logic_error("mutex hierarchy violated");
    }
    // 恢复前一线程的层级值
    this_thread_hierarchy_value = previous_hierarchy_value;
    internal_mutex.unlock();
  }
  bool try_lock()
  {
    check_for_hierarchy_violation();
    if (!internal_mutex.try_lock()) return false;
    update_hierarchy_value();
    return true;
  }
};

thread_local unsigned long // 初始化为ULONG_MAX以使构造锁时能通过检查
hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX);
```

* 看似复杂其实逻辑很简单，简化一下很容易理解

```cpp
class A {
  std::mutex m; // 内部锁
  int val; // 当前层级值
  int pre; // 用于保存前一线程层级值
  static thread_local int tVal; // tVal存活于一个线程周期
 public:
  explicit A(int x) : val(x), pre(0) {}
  void lock()
  {
    if (tVal > val)
    { // 存储线程层级值tVal到pre后将其更新为锁的层级值val
      m.lock();
      pre = tVal;
      tVal = val;
    }
    else
    {
      throw std::logic_error("mutex hierarchy violated");
    }
  }
  void unlock()
  { // 恢复线程层级值为pre
    if (tVal != val)
    {
      throw std::logic_error("mutex hierarchy violated");
    }
    tVal = pre;
    m.unlock();
  }
  bool try_lock()
  {
    if (tVal > val)
    {
      if (!m.try_lock()) return false;
      pre = tVal;
      tVal = val;
      return true;
    }
    else
    {
      throw std::logic_error("mutex hierarchy violated");
    }
  }
};

thread_local int A::tVal(INT_MAX); // 保证初始构造std::scoped_lock正常
```

* 解释之前的例子

```cpp
hierarchical_mutex high(10000);
hierarchical_mutex mid(6000);
hierarchical_mutex low(5000); // 构造一个层级锁
// 初始化时锁的层级值hierarchy_value为5000
// previous_hierarchy_value为0

void lf()
{
  std::scoped_lock l(low);
  // 用层级锁构造std::scoped_lock时会调用low.lock
  // lock先检查，this_thread_hierarchy_value初始化为ULONG_MAX
  // 因此this_thread_hierarchy_value大于hierarchy_value
  // 通过检查，内部锁上锁
  // 更新值，把previous_hierarchy_value更新为线程层级值ULONG_MAX
  // 把this_thread_hierarchy_value更新为low的层级值5000
} // 调用low.unlock，检查this_thread_hierarchy_value，值为5000
// 与hierarchy_value相等，通过检查
// 接着把this_thread_hierarchy_value恢复为pre保存的ULONG_MAX
// 最后解锁

void hf()
{
  std::scoped_lock l(high);
  // this_thread_hierarchy_value更新为high的层级值10000
  lf(); // 调用lf时，lf里的this_thread_hierarchy_value值为10000
  // 过程只是把lf中的注释里this_thread_hierarchy_value初始值改为10000
  // 同样能通过检查，其余过程一致，最后解锁lf会恢复到这里的线程层级值10000
}

void mf()
{
  std::scoped_lock l(mid);
  // this_thread_hierarchy_value更新为mid的层级值6000
  hf(); // 调用hf时，hf里的this_thread_hierarchy_value值为6000
  // 构造hf里的l时，调用high.lock
  // 检查this_thread_hierarchy_value，小于high.hierarchy_value
  // 于是throw std::logic_error("mutex hierarchy violated")
}
```

## 其他保护共享数据的可选方式

### 保护共享数据的初始化

* 一个极端但常见的情况是，共享数据在并发访问和初始化都需要保护，但之后要隐式同步。数据初始化后上锁只是为了保护初始化过程，但这会不必要地影响性能
* 延迟初始化在单线程中很常见

```cpp
std::shared_ptr<A> P;
void f()
{
  if (!p)
  {
    p.reset(new A); // 在多线程中这里需要保护
  }
  p->doSomething();
}
```

* 但在多线程直接上锁会导致不必要的线程资源阻塞

```cpp
std::shared_ptr<A> P;
std::mutex m;

void f()
{
  std::unique_lock<std::mutex> l(m); // 所有线程会在此处阻塞
  if (!p)
  {
    p.reset(new A);
  }
  l.unlock();
  p->doSomething();
}
```

* 很多人能想到一个更好的方法是双重检查锁模式

```cpp
void f()
{
  if (!p) // 这里没被锁保护，会与其他线程中被锁保护的reset竞争
  {
    std::scoped_lock l(m);
    if (!p)
    {
      p.reset(new A);
    }
  }
  p->doSomething();
}
```

* 但这个方案也存在潜在的race condition，第一次的检查没上锁，可能与其他线程中被保护的reset操作产生竞争。如果当前线程看见其他线程写入了指针，但没看到新创建的对象实例，调用doSomething就会出错

```cpp
p.reset(new A);
// 1. 为A对象分配一片内存
// 2. 在分配的内存上调用A的构造函数，构造一个A对象
// 3. 返回该内存的指针，让p指向该内存
// 编译器不一定按23顺序执行，可能32
```

* 为了处理race condition，C++标准库提供了[std::once_flag](https://en.cppreference.com/w/cpp/thread/once_flag)和[std::call_once](https://en.cppreference.com/w/cpp/thread/call_once)

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::once_flag flag;

void f()
{
  std::call_once(flag, [] { std::cout << 1; });
  std::cout << 2;
}

int main()
{
  std::thread t1(f);
  std::thread t2(f);
  std::thread t3(f);
  t1.join();
  t2.join();
  t3.join();
}

// output
1222
```

* 每个线程只要使用[std::call_once](https://en.cppreference.com/w/cpp/thread/call_once)，在[std::call_once](https://en.cppreference.com/w/cpp/thread/call_once)结束时就能安全地知道指针已被其他线程初始化，而且这比使用mutex的开销更小

```cpp
std::shared_ptr<A> p;
std::once_flag flag;

void init()
{
  p.reset(new A);
}

void f()
{
  std::call_once(flag, init);
  p->doSomething();
}
```

* [std::call_once](https://en.cppreference.com/w/cpp/thread/call_once)也可以用在类中

```cpp
class A {
 private:
  std::once_flag flag;
  void init() { ... }
 public:
  void f()
  {
    std::call_once(flag, &A::init, this);
    ...
  }
};
```

* static变量的初始化存在潜在的race condition：变量声明为static时，声明后就完成了初始化，一个线程完成了初始化，其他线程仍会抢着定义这个变量。为此，C++11规定static变量的初始化只完全发生在一个线程中，直到初始化完成前其他线程都不会做处理，从而避免了race condition。只有一个全局实例时可以不使用[std::call_once](https://en.cppreference.com/w/cpp/thread/call_once)而直接用static

```cpp
class A {
 public:
  static A& getInstance();
  A(const A&) = delete;
  A& operator(const A&) = delete;
 private:
  A() = default;
  ~A() = default;
};

A& A::getInstance()
{
  static A instance; // 线程安全的初始化
  return instance;
}
```

### 保护不常更新的数据结构

* 有些数据（比如缓存中存放的DNS入口表）需要经常访问但更新频率很低，如果用[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)保护数据有些过度（大量读的操作也会因锁而影响性能），这就需要用上读写锁（reader-writer mutex），它允许多个线程并发读但仅一个线程写
* C++17提供了[std::shared_mutex](https://en.cppreference.com/w/cpp/thread/shared_mutex)和[std::shared_timed_mutex](https://en.cppreference.com/w/cpp/thread/shared_timed_mutex)（C++14），后者比前者提供了更多操作，但前者性能更高。C++11没有提供读写锁，为此可使用[boost::shared_mutex](https://www.boost.org/doc/libs/1_71_0/doc/html/thread/synchronization.html#thread.synchronization.mutex_types.shared_mutex)
* 读写锁并不是万能的，其性能与处理器数量及读写线程的负载有关
* C++14提供了[std::shared_lock](https://en.cppreference.com/w/cpp/thread/shared_lock)，用法和[std::unique_lock](https://en.cppreference.com/w/cpp/thread/unique_lock)相同，此外[std::shared_lock](https://en.cppreference.com/w/cpp/thread/shared_lock)还允许多线程同时获取共享锁，因此一般用[std::shared_lock](https://en.cppreference.com/w/cpp/thread/shared_lock)锁定读，[std::unique_lock](https://en.cppreference.com/w/cpp/thread/unique_lock)锁定写

```cpp
class A {
 private:
  mutable std::shared_mutex m;
  int n = 0;
 public:
  int read()
  {
    std::shared_lock<std::shared_mutex> l(m);
    return n;
  }
  void write()
  {
    std::unique_lock<std::shared_mutex> l(m);
    ++n;
  }
};
```

### 递归锁

* 一个线程已经获取[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)（即已上锁）后再次上锁就会产生未定义行为

```cpp
std::mutex m;

void f()
{
  m.lock();
  m.unlock();
}

void g()
{
  m.lock();
  f();
  m.unlock();
}

int main()
{
  std::thread t(g);
  t.join(); // 产生未定义行为
}
```

* 为了允许这种情况，C++提供了[std::recursive_mutex](https://en.cppreference.com/w/cpp/thread/recursive_mutex)，它可以在一个线程上多次获取锁，但在其他线程获取锁之前必须释放所有的锁
* 多数情况下，如果需要递归锁，说明代码设计存在问题。比如一个类的每个成员函数都会上锁，一个成员函数调用另一个成员函数，就可能多次上锁，这种情况用递归锁就可以避免产生未定义行为。但显然这个设计本身是有问题的，更好的办法是提取其中一个函数作为private成员并且不上锁，其他成员先上锁再调用该函数
